{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3c21d9-02cf-4283-8410-fa5d0ed236bb",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a4ce0-2cfa-47c7-bd72-d02847c5ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost_ray as xgb\n",
    "from xgboost.core import QuantileDMatrix\n",
    "\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7124e6",
   "metadata": {},
   "source": [
    "## Setup a distributed cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8c839",
   "metadata": {},
   "source": [
    "### Login to the Openshift cluster   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "if os.environ[\"CLUSTER_ACCESS_TOKEN\"] != \"\":\n",
    "    auth = TokenAuthentication(\n",
    "        token = os.environ[\"CLUSTER_ACCESS_TOKEN\"],\n",
    "        server = \"https://api.mindaro.int.nefast.me:6443\",\n",
    "        skip_tls = True,\n",
    "    )\n",
    "    auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ffc2a",
   "metadata": {},
   "source": [
    "### Create a Ray cluster to distribute the workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = \"xgboost-distributed-cluster\"\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name=cluster_name,\n",
    "    namespace=\"ray\",\n",
    "    head_cpu_requests='250m',\n",
    "    head_cpu_limits=1,\n",
    "    head_memory_requests='250Mi',\n",
    "    head_memory_limits=6,\n",
    "    num_workers=2,\n",
    "    worker_cpu_requests='250m',\n",
    "    worker_cpu_limits=1,\n",
    "    worker_memory_requests='250Mi',\n",
    "    worker_memory_limits=6,\n",
    "    image=\"quay.io/modh/ray:2.44.1-py311-cu121\",\n",
    "    write_to_file=False, # When enabled Ray Cluster yaml files are written to /HOME/.codeflare/resources\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f727bc3",
   "metadata": {},
   "source": [
    "### Bring up the Ray cluster and print its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.up()\n",
    "cluster.wait_ready()\n",
    "cluster.details()\n",
    "\n",
    "ray_dashboard_uri = cluster.cluster_dashboard_uri()\n",
    "ray_cluster_uri = cluster.cluster_uri()\n",
    "print(ray_dashboard_uri)\n",
    "print(ray_cluster_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3bcef",
   "metadata": {},
   "source": [
    "### Bind Ray to the new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk import generate_cert\n",
    "\n",
    "# Create required TLS cert and export the environment variables to enable TLS\n",
    "generate_cert.generate_tls_cert(cluster_name, cluster.config.namespace)\n",
    "generate_cert.export_env(cluster_name, cluster.config.namespace)\n",
    "\n",
    "import ray\n",
    "\n",
    "ray_cluster_uri = \"ray://rayclient-xgboost-distributed-cluster-ray.apps.mindaro.int.nefast.me\"\n",
    "\n",
    "# Reset the ray context in case there's already one.\n",
    "print(\"Connecting to remote Ray cluster at: \", ray_cluster_uri)\n",
    "ray.shutdown()\n",
    "\n",
    "# Load dependencies to then install on the Ray cluster.\n",
    "with open(\"compute.requirements.txt\", \"r\") as f:\n",
    "    requirements = f.read().splitlines()\n",
    "\n",
    "runtime_env = {\"pip\": requirements}\n",
    "ray.init(address=ray_cluster_uri, runtime_env=runtime_env)\n",
    "\n",
    "print(\"Ray cluster is up and running: \", ray.is_initialized())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e9ede-380d-4610-8953-07ac83c7e98e",
   "metadata": {},
   "source": [
    "## Define the function that will have to be approximated through log. reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79723127-be20-4cc0-98cf-14e7629eee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return np.sin(x) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbecdeb-46e3-4c1e-b4d7-2a3b928589fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost_ray as xgb\n",
    "\n",
    "\"\"\"Train a quantile regression model.\"\"\"\n",
    "rng = np.random.RandomState(1994)\n",
    "# Generate a synthetic dataset for demo, the generate process is from the sklearn\n",
    "# example.\n",
    "X = np.atleast_2d(rng.uniform(0, 20.0, size=100000)).T\n",
    "expected_y = f(X).ravel()\n",
    "\n",
    "sigma = 0.5 + X.ravel() / 20.0\n",
    "noise = rng.lognormal(sigma=sigma) - np.exp(sigma**2.0 / 2.0)\n",
    "y = expected_y + noise\n",
    "\n",
    "# Train on 0.05 and 0.95 quantiles. The model is similar to multi-class and\n",
    "# multi-target models.\n",
    "alpha = np.array([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "evals_result: Dict[str, Dict] = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng, test_size=0.1)\n",
    "# We will be using the `hist` tree method, quantile DMatrix can be used to preserve\n",
    "# memory (which has nothing to do with quantile regression itself, see its document\n",
    "# for details).\n",
    "# Do not use the `exact` tree method for quantile regression, otherwise the\n",
    "# performance might drop.\n",
    "Xy = xgb.RayDMatrix(X_train, y_train)\n",
    "# use Xy as a reference\n",
    "Xy_test = xgb.RayDMatrix(X_test, y_test, ref=Xy)\n",
    "\n",
    "booster = xgb.train(\n",
    "    {\n",
    "        # Use the quantile objective function.\n",
    "        \"objective\": \"reg:quantileerror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"quantile_alpha\": alpha,\n",
    "        # Let's try not to overfit.\n",
    "        \"learning_rate\": 0.04,\n",
    "        \"max_depth\": 15,\n",
    "    },\n",
    "    Xy,\n",
    "    num_boost_round=32,\n",
    "    ray_params=xgb.RayParams(num_actors=2, cpus_per_actor=1),\n",
    "    early_stopping_rounds=2,\n",
    "    # The evaluation result is a weighted average across multiple quantiles.\n",
    "    evals=[(Xy, \"Train\"), (Xy_test, \"Test\")],\n",
    "    evals_result=evals_result,\n",
    ")\n",
    "xx = np.atleast_2d(np.linspace(0, 20, 100000)).T\n",
    "scores = booster.inplace_predict(xx)\n",
    "# dim 1 is the quantiles\n",
    "assert scores.shape[0] == xx.shape[0]\n",
    "assert scores.shape[1] == alpha.shape[0]\n",
    "\n",
    "y_lower = scores[:, 0]  # alpha=0.05\n",
    "y_med = scores[:, 1]  # alpha=0.5, median\n",
    "y_upper = scores[:, 2]  # alpha=0.95\n",
    "\n",
    "# Train a mse model for comparison\n",
    "booster = xgb.train(\n",
    "    {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        # Let's try not to overfit.\n",
    "        \"learning_rate\": 0.04,\n",
    "        \"max_depth\": 15,\n",
    "    },\n",
    "    Xy,\n",
    "    num_boost_round=32,\n",
    "    early_stopping_rounds=2,\n",
    "    evals=[(Xy, \"Train\"), (Xy_test, \"Test\")],\n",
    "    evals_result=evals_result,\n",
    "    ray_params=xgb.RayParams(num_actors=2, cpus_per_actor=1)\n",
    ")\n",
    "xx = np.atleast_2d(np.linspace(0, 20, 100000)).T\n",
    "y_pred = booster.inplace_predict(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60f517-cdbd-4e14-b296-657b1829d7ce",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c3650-5181-4d39-b3e1-059c52d30512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "plt.plot(xx, f(xx), \"g:\", linewidth=3, label=r\"$f(x) = x\\,\\sin(x)$\")\n",
    "plt.plot(X_test, y_test, \"b.\", markersize=10, label=\"Test observations\")\n",
    "plt.plot(xx, y_med, \"r-\", label=\"Predicted median\")\n",
    "plt.plot(xx, y_pred, \"m-\", label=\"Predicted mean\")\n",
    "plt.plot(xx, y_upper, \"k-\")\n",
    "plt.plot(xx, y_lower, \"k-\")\n",
    "plt.fill_between(\n",
    "    xx.ravel(), y_lower, y_upper, alpha=0.4, label=\"Predicted 90% interval\"\n",
    ")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f(x)$\")\n",
    "plt.ylim(-40, 40)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
